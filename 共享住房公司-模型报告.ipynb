{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 共享住房公司定价\n",
    "\n",
    "某共享住房公司（如Airbnb类公司）希望能够给不同房间需求制定价格，最终目的为最大化收益。在此过程中，此公司需要建立一个引擎预测不同房间需求在不同价格下面的购买情况。对此，此公司有一些历史数据如下：\n",
    "\n",
    "- ID：数据编号\n",
    "- Region: 房间所属区域（类型离散变量，取1-10内整数）\n",
    "- Date: 需求日期（1-365之间整数，这里我们考虑的需求都是假定为1天的需求）\n",
    "- Weekday：星期几（1-7之间整数）\n",
    "- Apartment/Room：是否是整个apartment还是只是一个房间（0-1变量）\n",
    "- #Beds: 床的数量（1-4之间整数）\n",
    "- Review：平均历史评价（连续变量，3-5之间实数）\n",
    "- Pic Quality：照片质量指标（连续变量，0-1之间实数）\n",
    "- Price：历史使用价格（连续变量，正实数）\n",
    "- Accept：历史上这个数据是否被接受\n",
    "\n",
    "\n",
    "目标：需找一个模型可以最好的通过变量和价格预测购买结果。在数据集Training Sheet中我们已经有实际的结果。任务为对Test Sheet集中的购买情况进行预测（Test Sheet中也有实际结果，我们只是在数据集中隐去了）。最终我们将用两个评判标准分别评判：\n",
    "\n",
    "- 评判标准1：对Test Data每一个进行0/1预测（也即在黄色区域填入0或者1），以正确数量进行评判，正确数量记为S2. \n",
    "- 评判标准2、对Test Data中每一个记录预测一个购买概率（也即在黄色区域填入一个概率值），以预测概率在真实情况下的log-likelihood 为评判标准。也即，如对第i条数据预测概率为pi，而第i条数据购买情况为Xi（Xi = 1表示实际购买了，Xi = 0表示实际未购买），则评价标准为：\n",
    "\n",
    "\\begin{equation}\n",
    "S_3 = \\sum_{i=0} （X_i*log(P_i)+ X_i*log(1-X_i)）\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 探索性数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>ApartmentRoom</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Twobedroom</th>\n",
       "      <th>Review</th>\n",
       "      <th>PicQuality</th>\n",
       "      <th>Price</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.906215</td>\n",
       "      <td>0.777532</td>\n",
       "      <td>419.342677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.927244</td>\n",
       "      <td>0.568539</td>\n",
       "      <td>511.447051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.448766</td>\n",
       "      <td>0.937857</td>\n",
       "      <td>336.708906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.797086</td>\n",
       "      <td>0.802913</td>\n",
       "      <td>317.400498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.024098</td>\n",
       "      <td>0.984053</td>\n",
       "      <td>280.088862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Region  Date  Weekday  ApartmentRoom  Beds  Twobedroom    Review  \\\n",
       "0   1       2     1        2              1     1           0  4.906215   \n",
       "1   2       7     1        2              1     4           0  4.927244   \n",
       "2   3       2     1        2              0     1           0  3.448766   \n",
       "3   4       5     1        2              1     1           0  3.797086   \n",
       "4   5       8     1        2              1     1           0  3.024098   \n",
       "\n",
       "   PicQuality       Price  Accept  \n",
       "0    0.777532  419.342677       0  \n",
       "1    0.568539  511.447051       1  \n",
       "2    0.937857  336.708906       0  \n",
       "3    0.802913  317.400498       0  \n",
       "4    0.984053  280.088862       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#载入包\n",
    "import numpy as np\n",
    "import pandas as pd                  \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "#载入数据\n",
    "data = pd.read_csv('traintwoRAWDATA.csv')\n",
    "data=data[:50000]\n",
    "display(data.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成交率 0.2924 未成交率 0.7076\n"
     ]
    }
   ],
   "source": [
    "#成交率\n",
    "success=len(data['ID'][data['Accept']==1])/50000.00\n",
    "#未成交率\n",
    "abort=1-success\n",
    "print '成交率',success,'未成交率',abort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出该共享住房公司数据未成交交易占比较大，超过70%， 而成功交易数据量占比较小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 原数据建模\n",
    "\n",
    "Logistic模型作为baseline模型，没有进行数据清洗（特征工程），5fold交叉检验下正确率为0.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73306661332266465"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "accepts = data['Accept']\n",
    "features = data.drop(['Accept','ID'], axis = 1)\n",
    "\n",
    "logit = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(logit,features,accepts,cv=5,scoring='accuracy')\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF模型在未清洗过的数据集上表现并不是很好，这有可能同数据集中 Nominal的时间数据并未处理有关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64056811362272448"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(min_samples_split=200) \n",
    "scores = cross_val_score(rf,features,accepts,cv=5,scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型二 Logistic 建模 （特征工程后）\n",
    "\n",
    "这部分将数值变量进行标准化，并将Region、Date等类别变量进行独热码编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd \n",
    "\n",
    "accepts  = data['Accept']\n",
    "features = data.drop(['Accept','ID'], axis = 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['Price', 'PicQuality','Review','Beds']\n",
    "features[numerical] = scaler.fit_transform(features[numerical])\n",
    "\n",
    "features['Region']= features['Region'].astype('str')\n",
    "features['Date']= features['Date'].astype('str')\n",
    "features['Weekday']= features['Weekday'].astype('str')\n",
    "features = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 经过特征工程后，再一次进行Logistic建模。\n",
    "- 模型准确率有小部分提高（0.003）\n",
    "### 模型提高不明显的原因是将 Date这一变量 one hot encode后，带来了大量的稀疏数据。且Date作为弱变量，并不能为模型做出显著贡献。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323064612922584"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(logit,features,accepts,cv=5,scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 除去Date变量后，模型表现提高到0.748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7481496299259851"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#除去Date变量进行建模\n",
    "accepts  = data['Accept']\n",
    "features = data.drop(['Accept','ID'], axis = 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['Price', 'PicQuality','Review','Beds']\n",
    "features[numerical] = scaler.fit_transform(features[numerical])\n",
    "\n",
    "features['Region']= features['Region'].astype('str')\n",
    "#features['Date']= features['Date'].astype('str')\n",
    "features['Weekday']= features['Weekday'].astype('str')\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "logit = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(logit,features,accepts,cv=5,scoring='accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型三 Logistic 建模 （特征工程+维度扩展）\n",
    "\n",
    "这一部分建模过程中， 增加了已有变量进行转换，目的是通过提升特征维度进而提升模型表现：\n",
    "- DayNum： 当日的数据点数目（无论接受与否）\n",
    "- Rate：当日接受的数据点数目\n",
    "- predictedPrice：使用除了价格外数据对价格进行回归，目的是得出在该特征下的预测价格\n",
    "- difference：(prices - predictedprice)/prices，实际价格偏离预测价格的大小\n",
    "- Twobedroom: 如果出租房屋且屋内有两张床（含）则为1，否则为0\n",
    "- LowReview：若Review评价为最低分（3），则为1，否则为0\n",
    "\n",
    "- 在5折交叉检验中，该模型预测准确度达0.751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/admin/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Region</th>\n",
       "      <th>Date</th>\n",
       "      <th>LowDate</th>\n",
       "      <th>HighDate</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>ApartmentRoom</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Review</th>\n",
       "      <th>LowReview</th>\n",
       "      <th>PicQuality</th>\n",
       "      <th>Price</th>\n",
       "      <th>LowPrice</th>\n",
       "      <th>HighPrice</th>\n",
       "      <th>Accept</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.906215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777532</td>\n",
       "      <td>419.342677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.927244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.568539</td>\n",
       "      <td>511.447051</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.448766</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937857</td>\n",
       "      <td>336.708906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.797086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802913</td>\n",
       "      <td>317.400498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.024098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984053</td>\n",
       "      <td>280.088862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Region  Date  LowDate  HighDate  Weekday  ApartmentRoom  Beds  \\\n",
       "0   1       2     1        0         0        2              1     1   \n",
       "1   2       7     1        0         0        2              1     4   \n",
       "2   3       2     1        0         0        2              0     1   \n",
       "3   4       5     1        0         0        2              1     1   \n",
       "4   5       8     1        0         0        2              1     1   \n",
       "\n",
       "     Review  LowReview  PicQuality       Price  LowPrice  HighPrice  Accept  \\\n",
       "0  4.906215          0    0.777532  419.342677         0          0       0   \n",
       "1  4.927244          0    0.568539  511.447051         0          1       1   \n",
       "2  3.448766          0    0.937857  336.708906         0          0       0   \n",
       "3  3.797086          0    0.802913  317.400498         0          0       0   \n",
       "4  3.024098          0    0.984053  280.088862         0          0       0   \n",
       "\n",
       "   DayNum  Rate  \n",
       "0     150    41  \n",
       "1     150    41  \n",
       "2     150    41  \n",
       "3     150    41  \n",
       "4     150    41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('trainingtwo.csv')\n",
    "data=data[:50000]\n",
    "\n",
    "data['DayNum']=0\n",
    "data['Rate'] =0\n",
    "for i in range(365):\n",
    "    data['DayNum'][data['Date']==i+1]=len(data['ID'][data['Date']==i+1])\n",
    "    data['Rate'][data['Date']==i+1]=len(data['ID'][data['Date']==i+1][data['Accept']==1])\n",
    "display(data.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>LowDate</th>\n",
       "      <th>ApartmentRoom</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Review</th>\n",
       "      <th>LowReview</th>\n",
       "      <th>PicQuality</th>\n",
       "      <th>Price</th>\n",
       "      <th>Region_1</th>\n",
       "      <th>Region_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Region_7</th>\n",
       "      <th>Region_8</th>\n",
       "      <th>Region_9</th>\n",
       "      <th>Weekday_1</th>\n",
       "      <th>Weekday_2</th>\n",
       "      <th>Weekday_3</th>\n",
       "      <th>Weekday_4</th>\n",
       "      <th>Weekday_5</th>\n",
       "      <th>Weekday_6</th>\n",
       "      <th>Weekday_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.953111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775070</td>\n",
       "      <td>0.523818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.963626</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563758</td>\n",
       "      <td>0.665992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937175</td>\n",
       "      <td>0.396262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>0.366457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983884</td>\n",
       "      <td>0.308862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date  LowDate  ApartmentRoom  Beds    Review  LowReview  PicQuality  \\\n",
       "0     1        0              1     0  0.953111          0    0.775070   \n",
       "1     1        0              1     1  0.963626          0    0.563758   \n",
       "2     1        0              0     0  0.224384          0    0.937175   \n",
       "3     1        0              1     0  0.398545          0    0.800733   \n",
       "4     1        0              1     0  0.012049          0    0.983884   \n",
       "\n",
       "      Price  Region_1  Region_10    ...      Region_7  Region_8  Region_9  \\\n",
       "0  0.523818         0          0    ...             0         0         0   \n",
       "1  0.665992         0          0    ...             1         0         0   \n",
       "2  0.396262         0          0    ...             0         0         0   \n",
       "3  0.366457         0          0    ...             0         0         0   \n",
       "4  0.308862         0          0    ...             0         1         0   \n",
       "\n",
       "   Weekday_1  Weekday_2  Weekday_3  Weekday_4  Weekday_5  Weekday_6  Weekday_7  \n",
       "0          0          1          0          0          0          0          0  \n",
       "1          0          1          0          0          0          0          0  \n",
       "2          0          1          0          0          0          0          0  \n",
       "3          0          1          0          0          0          0          0  \n",
       "4          0          1          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516\n",
      "0.7494\n",
      "0.7214\n",
      "0.7008\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from pylightgbm.models import GBMClassifier\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split\n",
    "execpath= \"/Users/admin/code/LightGBM/lightgbm\"\n",
    "\n",
    "\n",
    "data = pd.read_csv('trainingtwo.csv')\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "data=data[:50000]\n",
    "\n",
    "prices = data['Price']\n",
    "features = data.drop(['Accept','ID','Price','Date'], axis = 1)\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['PicQuality','Review','Beds']\n",
    "features[numerical] = scaler.fit_transform(features[numerical])\n",
    "\n",
    "\n",
    "\n",
    "Accept = data['Accept']\n",
    "features = data.drop(['Accept','ID'], axis = 1)\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['Price', 'PicQuality','Review','Beds']\n",
    "features[numerical] = scaler.fit_transform(features[numerical])\n",
    "\n",
    "features['Region']= features['Region'].astype('str')\n",
    "#features['Date']= features['Date'].astype('str')\n",
    "features['Weekday']= features['Weekday'].astype('str')\n",
    "features = pd.get_dummies(features)\n",
    "features = features.drop(['HighPrice','LowPrice'], axis = 1)\n",
    "features = features.drop(['HighDate'], axis = 1)\n",
    "\n",
    "display(features.head(n=5))\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, Accept, test_size=0.2, random_state = 0)\n",
    "\n",
    "#建立Logistics\n",
    "logit = linear_model.LogisticRegression(C=2000,solver='newton-cg',penalty='l2')\n",
    "logit.fit(x_train,y_train)\n",
    "predictions = logit.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores\n",
    "\n",
    "logit = linear_model.LogisticRegression(C=1000,solver='newton-cg',penalty='l2')\n",
    "scores = cross_val_score(logit,features,Accept,cv=5,scoring='accuracy')\n",
    "print scores.mean()\n",
    "\n",
    "rf = RandomForestClassifier() \n",
    "rf.fit(x_train,y_train)\n",
    "predictions = rf.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores\n",
    "\n",
    "clf = GBMClassifier(exec_path=execpath, application='binary' ,boosting_type='gbdt',is_unbalance=True, verbose=False)\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    4.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "params = {'n_neighbors':[3,5,10,20]}\n",
    "grid = GridSearchCV(neigh, params,'accuracy',n_jobs=1,verbose=1)\n",
    "grid = grid.fit(x_train, y_train)\n",
    "print(grid.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70899999999999996"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh =KNeighborsClassifier(n_neighbors=500)\n",
    "neigh.fit(x_train, y_train) \n",
    "predictions_test=neigh.predict(x_test)\n",
    "accuracy_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GBMClassifier(exec_path=execpath, application='binary' ,boosting_type='gbdt',is_unbalance=True, verbose=False)\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores\n",
    "\n",
    "svc = svm.LinearSVC()\n",
    "svc.fit(x_train,y_train)\n",
    "svpredictions = svc.predict(x_test)\n",
    "svscores = accuracy_score(y_test, svpredictions)\n",
    "\n",
    "sv = svm.SVC(kernel='linear')\n",
    "sv.fit(x_train,y_train)\n",
    "svpredictions = sv.predict(x_test)\n",
    "svscores = accuracy_score(y_test, svpredictions)\n",
    "print svscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7493\n"
     ]
    }
   ],
   "source": [
    "sv = svm.SVC(C=2,kernel='linear')\n",
    "sv.fit(x_train,y_train)\n",
    "svpredictions = sv.predict(x_test)\n",
    "svscores = accuracy_score(y_test, svpredictions)\n",
    "print svscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7002\n"
     ]
    }
   ],
   "source": [
    "clf = GBMClassifier(exec_path=execpath, application='binary' ,boosting_type='gbdt',is_unbalance=True, verbose=False,)\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(min_samples_split=100) \n",
    "rf.fit(x_train,y_train)\n",
    "predictions = rf.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-183643a6a27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgsearch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgsearch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score'"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "param_test = {'max_depth':range(3,16,2), 'min_samples_split':range(50,201,20)}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 60, min_samples_leaf=20, random_state=10),param_grid = param_test, scoring='accuracy',iid=False, cv=5)\n",
    "\n",
    "gsearch2.fit(features, Accept)\n",
    "gsearch2.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.70162, std: 0.01176, params: {'min_samples_split': 50, 'max_depth': 3},\n",
       " mean: 0.70176, std: 0.01148, params: {'min_samples_split': 70, 'max_depth': 3},\n",
       " mean: 0.70122, std: 0.01256, params: {'min_samples_split': 90, 'max_depth': 3},\n",
       " mean: 0.70122, std: 0.01256, params: {'min_samples_split': 110, 'max_depth': 3},\n",
       " mean: 0.70122, std: 0.01256, params: {'min_samples_split': 130, 'max_depth': 3},\n",
       " mean: 0.70122, std: 0.01256, params: {'min_samples_split': 150, 'max_depth': 3},\n",
       " mean: 0.70122, std: 0.01256, params: {'min_samples_split': 170, 'max_depth': 3},\n",
       " mean: 0.70122, std: 0.01256, params: {'min_samples_split': 190, 'max_depth': 3},\n",
       " mean: 0.70282, std: 0.01982, params: {'min_samples_split': 50, 'max_depth': 5},\n",
       " mean: 0.70224, std: 0.02044, params: {'min_samples_split': 70, 'max_depth': 5},\n",
       " mean: 0.70342, std: 0.01882, params: {'min_samples_split': 90, 'max_depth': 5},\n",
       " mean: 0.70336, std: 0.01976, params: {'min_samples_split': 110, 'max_depth': 5},\n",
       " mean: 0.70246, std: 0.02138, params: {'min_samples_split': 130, 'max_depth': 5},\n",
       " mean: 0.70226, std: 0.02102, params: {'min_samples_split': 150, 'max_depth': 5},\n",
       " mean: 0.70170, std: 0.02125, params: {'min_samples_split': 170, 'max_depth': 5},\n",
       " mean: 0.70130, std: 0.02307, params: {'min_samples_split': 190, 'max_depth': 5},\n",
       " mean: 0.70660, std: 0.02330, params: {'min_samples_split': 50, 'max_depth': 7},\n",
       " mean: 0.70314, std: 0.02876, params: {'min_samples_split': 70, 'max_depth': 7},\n",
       " mean: 0.70648, std: 0.02280, params: {'min_samples_split': 90, 'max_depth': 7},\n",
       " mean: 0.70508, std: 0.02391, params: {'min_samples_split': 110, 'max_depth': 7},\n",
       " mean: 0.70426, std: 0.02533, params: {'min_samples_split': 130, 'max_depth': 7},\n",
       " mean: 0.70614, std: 0.02145, params: {'min_samples_split': 150, 'max_depth': 7},\n",
       " mean: 0.70586, std: 0.02365, params: {'min_samples_split': 170, 'max_depth': 7},\n",
       " mean: 0.70566, std: 0.02325, params: {'min_samples_split': 190, 'max_depth': 7},\n",
       " mean: 0.71308, std: 0.02432, params: {'min_samples_split': 50, 'max_depth': 9},\n",
       " mean: 0.71302, std: 0.02529, params: {'min_samples_split': 70, 'max_depth': 9},\n",
       " mean: 0.71158, std: 0.02629, params: {'min_samples_split': 90, 'max_depth': 9},\n",
       " mean: 0.71376, std: 0.02125, params: {'min_samples_split': 110, 'max_depth': 9},\n",
       " mean: 0.71226, std: 0.02450, params: {'min_samples_split': 130, 'max_depth': 9},\n",
       " mean: 0.71384, std: 0.02440, params: {'min_samples_split': 150, 'max_depth': 9},\n",
       " mean: 0.71336, std: 0.02629, params: {'min_samples_split': 170, 'max_depth': 9},\n",
       " mean: 0.71262, std: 0.02656, params: {'min_samples_split': 190, 'max_depth': 9},\n",
       " mean: 0.71962, std: 0.02513, params: {'min_samples_split': 50, 'max_depth': 11},\n",
       " mean: 0.71782, std: 0.02804, params: {'min_samples_split': 70, 'max_depth': 11},\n",
       " mean: 0.71196, std: 0.03833, params: {'min_samples_split': 90, 'max_depth': 11},\n",
       " mean: 0.71684, std: 0.02847, params: {'min_samples_split': 110, 'max_depth': 11},\n",
       " mean: 0.71320, std: 0.03224, params: {'min_samples_split': 130, 'max_depth': 11},\n",
       " mean: 0.71880, std: 0.02617, params: {'min_samples_split': 150, 'max_depth': 11},\n",
       " mean: 0.71794, std: 0.02609, params: {'min_samples_split': 170, 'max_depth': 11},\n",
       " mean: 0.71606, std: 0.03005, params: {'min_samples_split': 190, 'max_depth': 11},\n",
       " mean: 0.71532, std: 0.03792, params: {'min_samples_split': 50, 'max_depth': 13},\n",
       " mean: 0.71838, std: 0.03026, params: {'min_samples_split': 70, 'max_depth': 13},\n",
       " mean: 0.71794, std: 0.03287, params: {'min_samples_split': 90, 'max_depth': 13},\n",
       " mean: 0.71720, std: 0.03180, params: {'min_samples_split': 110, 'max_depth': 13},\n",
       " mean: 0.71894, std: 0.02999, params: {'min_samples_split': 130, 'max_depth': 13},\n",
       " mean: 0.71736, std: 0.03028, params: {'min_samples_split': 150, 'max_depth': 13},\n",
       " mean: 0.71794, std: 0.02693, params: {'min_samples_split': 170, 'max_depth': 13},\n",
       " mean: 0.71718, std: 0.02985, params: {'min_samples_split': 190, 'max_depth': 13},\n",
       " mean: 0.71670, std: 0.03648, params: {'min_samples_split': 50, 'max_depth': 15},\n",
       " mean: 0.72200, std: 0.02506, params: {'min_samples_split': 70, 'max_depth': 15},\n",
       " mean: 0.72216, std: 0.02551, params: {'min_samples_split': 90, 'max_depth': 15},\n",
       " mean: 0.72142, std: 0.02636, params: {'min_samples_split': 110, 'max_depth': 15},\n",
       " mean: 0.71588, std: 0.03734, params: {'min_samples_split': 130, 'max_depth': 15},\n",
       " mean: 0.71810, std: 0.03212, params: {'min_samples_split': 150, 'max_depth': 15},\n",
       " mean: 0.71546, std: 0.03794, params: {'min_samples_split': 170, 'max_depth': 15},\n",
       " mean: 0.71700, std: 0.03259, params: {'min_samples_split': 190, 'max_depth': 15}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sv = svm.SVC(kernel='linear'，)\n",
    "sv.fit(x_train,y_train)\n",
    "svpredictions = sv.predict(x_test)\n",
    "svscores = accuracy_score(y_test, svpredictions)\n",
    "print svscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {'n_estimators':range(10,71,10)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(min_samples_split=100,\n",
    "                                  min_samples_leaf=20,max_depth=8,max_features='sqrt' ,random_state=10), \n",
    "                       param_grid = param_test1, scoring='roc_auc',cv=5)\n",
    "gsearch1.fit(X,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApartmentRoom</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Twobedroom</th>\n",
       "      <th>Review</th>\n",
       "      <th>LowReview</th>\n",
       "      <th>PicQuality</th>\n",
       "      <th>Price</th>\n",
       "      <th>L0</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>...</th>\n",
       "      <th>Region_7</th>\n",
       "      <th>Region_8</th>\n",
       "      <th>Region_9</th>\n",
       "      <th>Weekday_1</th>\n",
       "      <th>Weekday_2</th>\n",
       "      <th>Weekday_3</th>\n",
       "      <th>Weekday_4</th>\n",
       "      <th>Weekday_5</th>\n",
       "      <th>Weekday_6</th>\n",
       "      <th>Weekday_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.906215</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775070</td>\n",
       "      <td>419.342677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.927244</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563758</td>\n",
       "      <td>511.447051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.448766</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937175</td>\n",
       "      <td>336.708906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.797086</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800733</td>\n",
       "      <td>317.400498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.024098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.983884</td>\n",
       "      <td>280.088862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApartmentRoom  Beds  Twobedroom    Review  LowReview  PicQuality  \\\n",
       "0              1     0           0  4.906215          0    0.775070   \n",
       "1              1     1           0  4.927244          0    0.563758   \n",
       "2              0     0           0  3.448766          0    0.937175   \n",
       "3              1     0           0  3.797086          0    0.800733   \n",
       "4              1     0           0  3.024098          0    0.983884   \n",
       "\n",
       "        Price  L0  L1  L2    ...      Region_7  Region_8  Region_9  Weekday_1  \\\n",
       "0  419.342677   0   0   0    ...             0         0         0          0   \n",
       "1  511.447051   0   0   0    ...             1         0         0          0   \n",
       "2  336.708906   0   0   0    ...             0         0         0          0   \n",
       "3  317.400498   0   0   0    ...             0         0         0          0   \n",
       "4  280.088862   0   0   0    ...             0         1         0          0   \n",
       "\n",
       "   Weekday_2  Weekday_3  Weekday_4  Weekday_5  Weekday_6  Weekday_7  \n",
       "0          1          0          0          0          0          0  \n",
       "1          1          0          0          0          0          0  \n",
       "2          1          0          0          0          0          0  \n",
       "3          1          0          0          0          0          0  \n",
       "4          1          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711142228446\n",
      "0.722644528906\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "data = pd.read_csv('trainingtwo2.csv')\n",
    "data=data[:49990]\n",
    "prices = data['Price']\n",
    "#display(data.head(n=5))\n",
    "features = data.drop(['Accept','ID','Price','Date','Region','Weekday','Twobedroom','LowReview','ApartmentRoom','L0','L1','L2','L3','L4','L5','L6','L7','L8','L9','L10'], axis = 1)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "#display(features.head(n=5))\n",
    "\n",
    "acceptdata = pd.read_csv('accept3.csv')\n",
    "acceptprices = acceptdata['Price']\n",
    "acceptfeature = acceptdata.drop(['Price','ApartmentRoom','ID'], axis = 1)\n",
    "#display(acceptfeature.head(n=5))\n",
    "#display(features.head(n=5))\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(acceptfeature, acceptprices)\n",
    "predictedprice=reg.predict(features)\n",
    "data['predictedPrice']= predictedprice\n",
    "data['difference']= (prices - predictedprice)/predictedprice\n",
    "\n",
    "\n",
    "accepts  = data['Accept']\n",
    "features = data.drop(['Accept','ID','Date'], axis = 1)\n",
    "features['Region']= features['Region'].astype('str')\n",
    "features['Weekday']= features['Weekday'].astype('str')\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical =['Beds','PicQuality']\n",
    "features[numerical] = scaler.fit_transform(features[numerical])\n",
    "display(features.head(n=5))\n",
    "\n",
    "#logit = linear_model.LogisticRegression()\n",
    "#scores = cross_val_score(logit,features,accepts,cv=5,scoring='accuracy')#print scores.mean()\n",
    "\n",
    "#rf = RandomForestClassifier() \n",
    "#rfscores=cross_val_score(rf,features,accepts,cv=5,scoring='accuracy')\n",
    "#print rfscores.mean()\n",
    "\n",
    "execpath= \"/Users/admin/code/LightGBM/lightgbm\"\n",
    "\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(features, accepts, test_size=0.2, random_state = 0)\n",
    "clf = GBMClassifier(exec_path=execpath, boosting_type='dart',is_unbalance=True, verbose=False)\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores\n",
    "\n",
    "clf = GBMClassifier(exec_path=execpath, num_iterations=1000, num_leaves=1024,max_bin=1000,application='binary' ,boosting_type='gbdt',is_unbalance=True, verbose=False)\n",
    "clf.fit(x_train,y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727445489098\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xg = xgb.XGBClassifier(n_estimators= 1000, max_depth= 13)\n",
    "xg.fit(x_train,  y_train)\n",
    "predictions = xg.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728045609122\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBClassifier(n_estimators= 2000, max_depth= 8)\n",
    "xgb.fit(x_train,  y_train)\n",
    "predictions = xgb.predict(x_test)\n",
    "scores = accuracy_score(y_test, predictions)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ApartmentRoom</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Review</th>\n",
       "      <th>PicQuality</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9235</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.154231</td>\n",
       "      <td>0.897629</td>\n",
       "      <td>480.064853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18373</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.592062</td>\n",
       "      <td>0.508191</td>\n",
       "      <td>411.787320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22859</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.923909</td>\n",
       "      <td>0.892040</td>\n",
       "      <td>533.212973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44539</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.731298</td>\n",
       "      <td>0.695569</td>\n",
       "      <td>265.842812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14643</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.755759</td>\n",
       "      <td>0.105415</td>\n",
       "      <td>247.631903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  ApartmentRoom  Beds    Review  PicQuality       Price\n",
       "0   9235              1     4  4.154231    0.897629  480.064853\n",
       "1  18373              1     2  4.592062    0.508191  411.787320\n",
       "2  22859              1     4  4.923909    0.892040  533.212973\n",
       "3  44539              1     3  4.731298    0.695569  265.842812\n",
       "4  14643              0     1  4.755759    0.105415  247.631903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(acceptdata.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型输出\n",
    "\n",
    "这一部分我们在所有训练集（50000条数据）上建立模型3， 并输出预测（0，1）和预测概率（Accept=1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/admin/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#将训练和测试集同时读入\n",
    "data = pd.read_csv('totaltwo.csv')\n",
    "data=data[:70000]\n",
    "\n",
    "#变量扩展\n",
    "data['DayNum']=0\n",
    "data['Rate'] =0\n",
    "for i in range(365):\n",
    "    data['DayNum'][data['Date']==i+1]=len(data['ID'][data['Date']==i+1])\n",
    "    data['Rate'][data['Date']==i+1]=len(data['ID'][data['Date']==i+1][data['Accept']==1])\n",
    "\n",
    "#使用回归预测价格\n",
    "prices = data['Price']\n",
    "features = data.drop(['Accept','ID','Price','Date'], axis = 1)\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['PicQuality','Review','Beds','DayNum','Rate']\n",
    "features[numerical] = scaler.fit_transform(features[numerical])\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(features, prices) \n",
    "predictedprice=reg.predict(features)\n",
    "\n",
    "#变量扩展：预测价格与价格差\n",
    "data['predictedPrice']= predictedprice\n",
    "data['difference']= (prices - predictedprice)/prices\n",
    "\n",
    "#删除预测价格变量，保留价格差，避免 multilinearity\n",
    "accept = data['Accept'][:50000]\n",
    "features = data.drop(['Accept','ID','predictedPrice'], axis = 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['Price', 'PicQuality','Review','Beds','difference','DayNum','Rate']\n",
    "features[numerical] = scaler.fit_transform(features[numerical])\n",
    "\n",
    "#独热码编码\n",
    "features['Region']= features['Region'].astype('str')\n",
    "features['Weekday']= features['Weekday'].astype('str')\n",
    "features = pd.get_dummies(features)\n",
    "#除去冗余变量\n",
    "features = features.drop(['Date','Twobedroom'], axis = 1)\n",
    "\n",
    "testfeatures =features[50000:]\n",
    "features =features[:50000]\n",
    "\n",
    "#建立Logistics\n",
    "logit = linear_model.LogisticRegression(C=2000,solver='newton-cg',penalty='l2')\n",
    "logit.fit(features,accept)\n",
    "predictions = logit.predict(testfeatures)\n",
    "preprob = logit.predict_proba(testfeatures)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#将预测结果写入到csv文件中\n",
    "import csv\n",
    "csvfile = file('case_two_pred.csv', 'wb')\n",
    "writer = csv.writer(csvfile)\n",
    "for i in predictions:\n",
    "    writer.writerow([i])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输出概率\n",
    "csvfile = file('case_two_prob.csv', 'wb')\n",
    "writer = csv.writer(csvfile)\n",
    "for i in preprob:\n",
    "    writer.writerow([i])\n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
